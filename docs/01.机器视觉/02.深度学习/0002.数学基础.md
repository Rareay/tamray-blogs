---
title: 数学基础
date: 2019-08-19 10:16:38
permalink: /pages/c35cac/
categories: 
  - 机器视觉
  - 深度学习
tags: 
  - 
---

## 1 线性代数

### 行列式

符号：
$
\begin{vmatrix}
a & b \\
c & d
\end{vmatrix}
$

$n$ 阶行列式的求法：
$$
D = 
\begin{vmatrix}
a_{11} & a_{12} & \ldots & a_{1n} \\
a_{21} & a_{22} & \ldots & a_{2n} \\
\vdots & \vdots &        & \vdots \\
a_{n1} & a_{n2} & \ldots & a_{nn}
\end{vmatrix} = 
\sum(-1)^t a_{1p1a} a_{2p2} \ldots a_{npn}
$$

上三角、下三角的行列式等于对角元素的乘积；
对角行列式等于对角元素的乘积；

行列式的性质：
- $D = D^T$ ，行列式 $D$ 等于其转置的行列式
- 对换行列式的两行（列），行列式变号
  即：如果有两行（列）完全相同，则行列式为 $0$ 
- 行列式的某一行（列）乘以 $k$，等于行列式乘以 $k$
  即：可以提取行列式某行（列）的因数出来
- 行列式中有两行（列）元素成比例，则行列式等于 $0$
- 行列式可以这样拆分：
  $$
  \begin{aligned}
  D 
  &= 
  \begin{vmatrix}
  a_{11} & a_{12} & \ldots & a_{1n} \\
  \vdots & \vdots &        & \vdots  \\
  a_{i1} + a'_{i1} & a_{i2} + a'_{i2} & \ldots & a_{in} + a'_{in} \\
  \vdots & \vdots &        & \vdots \\
  a_{n1} & a_{n2} & \ldots & a_{nn}
  \end{vmatrix} \\
  &=
  \begin{vmatrix}
  a_{11} & a_{12} & \ldots & a_{1n} \\
  \vdots & \vdots &        & \vdots \\
  a_{i1} & a_{i2} & \ldots & a_{in} \\
  \vdots & \vdots &        & \vdots \\
  a_{n1} & a_{n2} & \ldots & a_{nn}
  \end{vmatrix}
  + 
  \begin{vmatrix}
  a_{11} & a_{12} & \ldots & a_{1n} \\
  \vdots & \vdots &        & \vdots  \\
  a'_{i1} & a'_{i2} & \ldots & a'_{in} \\
  \vdots & \vdots &        & \vdots \\
  a_{n1} & a_{n2} & \ldots & a_{nn}
  \end{vmatrix}
  \end{aligned}
  $$
- 行列式的行（列）与行（列）之间可以相互加减

余子式：对于元素 $(i,j)$，去除第 $i$ 行 $j$ 列的所有元素后，剩下的元素就是它的余子式 $M_{ij}$
代数余子式：$A_{ij} = (-1)^{i+j} M_{ij}$
定理：
- 对于 $n$ 阶行列式，如果其中第 $i$ 行的所有元素中除了 $(i,j)$ 元素外，其他的都为 $0$，那么行列式：
  $$D = a_{ij}A_{ij}$$
- 行列式等于它的任一行（列）的各个元素与其对应的代数余子式乘积之和：
  $$D = a_{i1}A_{i1} + a_{i2}A_{i2} + \ldots + a_{in}A_{in}, \ \ \ i = 1,2\ldots,n $$
- 行列式某一行（列）的元素与另一行（列）的对应元素的代数余子式乘积之和等于 $0$
  $$a_{1j}A_{1j} + a_{2i}A_{2j} + \ldots + a_{ni}A_{nj} = 0, \ \ \ i \neq j $$


### 矩阵

非齐次线性方程组
齐次线性方程组
`行矩阵`也称为`行向量`
`列矩阵`也称为`列向量`
矩阵变换是线性变换的一种表达形式，记作：$y = Ax$，其中，$y$、$x$ 是列向量（列矩阵），$A$ 是变换矩阵
对角矩阵：
$$
\Lambda = 
\begin{bmatrix}
\lambda_1 & 0 & \ldots & 0 \\
0 & \lambda_2 & \ldots & 0 \\
\vdots & \vdots &  & \vdots \\
0 & 0 & \ldots & \lambda_n \\
\end{bmatrix}
$$

矩阵的运算：
$$A + B = B + A$$
$$(A + B) + C = A + (B + C)$$
$$(AB)C = A(BC)$$
$$\lambda(AB) = (\lambda A)B = A(\lambda B)$$
$$A(B + C) = AB + AC, \ \ \  (B + C)A = BA + CA$$
转置：
$$(A^T)^T = A$$
$$(A + B)^T = A^T + B^T$$
$$(\lambda A)^T = \lambda A^T$$
$$(AB)^T = B^T A^T$$

方阵 $A$ 的行列式记为 $detA$ 或 $\begin{vmatrix} A \end{vmatrix}$，注意，方阵是矩阵，其对应元素组成的行列式才可作行列式的相关与运算，这里强调一下矩阵和行列式性质有所不同，书写的符号也不一样
方阵的行列式的性质：
$$\begin{vmatrix} A^T \end{vmatrix} = \begin{vmatrix} A \end{vmatrix}$$
$$\begin{vmatrix} \lambda A\end{vmatrix} = \lambda ^ n\begin{vmatrix} A \end{vmatrix}$$
$$\begin{vmatrix} AB \end{vmatrix} = \begin{vmatrix} A \end{vmatrix} \begin{vmatrix} B \end{vmatrix}$$

逆矩阵定理：
- 若矩阵 $A$ 可逆，则 $\begin{vmatrix} A \end{vmatrix} \neq 0$
- 若 $\begin{vmatrix} A \end{vmatrix} \neq 0$，则矩阵 $A$ 可逆，且（$A^*$为伴随矩阵）：
  $$A^{-1} = \frac{1}{\begin{vmatrix} A \end{vmatrix}} A^*$$

克拉默法则：
如果线性方程组的系数矩阵 $A$ 的行列式不等于 $0$，那么方程有唯一解（式子就不列出来了）


### 特征值和特征向量

对于方阵 $A$，满足：
$$Ap=\lambda p;p\neq0$$
的数 $\lambda$ 和向量 $p$ 分别为 *特征值* 和 *特征向量*。


### 特征值的计算


- 对角矩阵的特征值就是对角元素
- 上三角矩阵的特征值就是对角元素
- 特征值可能含有复数
- 求 $A=\begin{bmatrix}3&-2\\1&0\end{bmatrix}$的特征值：
  $$\begin{aligned} 
  \phi_A(\lambda)
  &=det 
  \begin{bmatrix}
  \lambda-3 & 2 \\
  -1 & \lambda
  \end{bmatrix} \\
  &=(\lambda-3)\lambda-2*(-1) \\
  &=\lambda^2-3\lambda+2 \\
  &=(\lambda - 1)(\lambda - 2)
  \end{aligned}$$
  解得特征值为 $1$ 和 $2$

### 特征向量的计算
将特征值依次代入 $Ap=\lambda p$，解出的各个列向量就是特征向量。
















## 2 概率论
### 2.1 概率分布
#### 2.1.1 概率的表示

- $P(X = x)$ 表示 $x$ 的概率，也记为 $P(x)$；

#### 2.1.2 联合概率

- $P(X = x, Y = y)$ ，记为 $P(x,y)$

> 表示 $X = x$ 和 $Y = y$ 同时发生的概率；

#### 2.1.3 边缘概率
- $P(X = x)$ 记为 $P(x)$

> 如何用`联合概率`来求`边缘概率`呢？可以这样子：
> $$P(x) =\sum_{y}^{} P(x, y)$$
> 意思就是在 $x$ 事件发生前提下，把 $y$ 发生的所有情况的概率累加起来，如果用积分的方式表达：
> $$P(x) = \int P(x, y)dy$$


#### 2.1.4 条件概率
- $P(Y = y|X=x)$ 记为 $P(y|x)$

> 表示在事件 $x$ 发生的条件下 $y$ 事件发生的概率，注意上面表达式中，条件事件在右边，其含义用公式表示：
> $$P(y|x)=\frac{P(y,x)}{P(x)}$$

#### 2.1.5 条件概率的链式法则

- $P(x^1,...,x^n)=P(x^1)\prod_{i=2}^{n}P(x^i|x^1,...,x^{i-1}))$

> 有下面的例子：
> $$P(a,b,c)=P(a|a,b)P(a,b)$$ 
> $$P(a,b)=P(a|b)P(b)$$ 
> $$P(a,b,c)=P(a|a,b)P(a|b)P(b)$$

#### 2.1.6 独立性和条件独立性
- 独立性
 如果满足下面条件就说明满足独立性：
$$P(a,b)=P(a)P(b)$$
- 条件独立性
  如果满足下面条件就说明满足条件独立性：
$$P(a,b|c)=P(a|c)P(b|c)$$
#### 2.1.7 期望、方差和协方差
- 期望
 1.离散型：
 $$\mathbb{E}_{x\thicksim P}\begin{bmatrix}f(x)\end{bmatrix}=\sum P(x)f(x)$$
 2.连续型：
 $$\mathbb{E}_{x\thicksim p}\begin{bmatrix}f(x)\end{bmatrix}=\int p(x)f(x)dx$$
- 方差
 $$Var(f(x))=\mathbb{E}\begin{bmatrix}(f(x)-\mathbb{E}\begin{bmatrix}f(x)\end{bmatrix})^2 \end{bmatrix}$$
- 协方差
  $$Cov(f(x),g(y))=\mathbb{E}\begin{bmatrix}(f(x)-\mathbb{E}\begin{bmatrix}f(x)\end{bmatrix}     )(g(y)-\mathbb{E} \begin{bmatrix}g(y)\end{bmatrix}    )\end{bmatrix}$$
#### 2.1.8 常用概率分布
